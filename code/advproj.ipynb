{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AAMEi-9clGZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754ff3f7-1cf4-4370-cbe5-4d56cc7c39d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch Mahdi https://github.com/raphaeltremblay/IFT6759-Advanced-Project.git"
      ],
      "metadata": {
        "id": "hlhOipv2lQg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0aebdbb-0030-41da-cfd5-863369e3cf4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IFT6759-Advanced-Project'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 431 (delta 78), reused 27 (delta 15), pack-reused 313\u001b[K\n",
            "Receiving objects: 100% (431/431), 219.93 MiB | 25.02 MiB/s, done.\n",
            "Resolving deltas: 100% (280/280), done.\n",
            "Updating files: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"./IFT6759-Advanced-Project/code\")"
      ],
      "metadata": {
        "id": "UpZVEnnJyTYy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "fmRDpC8s0PjS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gensim.__version__)"
      ],
      "metadata": {
        "id": "EkGKoPv2pB3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e787681-47f5-4498-a258-79239c7c2ecf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==4.3.1"
      ],
      "metadata": {
        "id": "MxRLCqWMpOQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572ba3d7-83e2-4045-ad69-ffd878f6f783"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim==4.3.1 in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim==4.3.1) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim==4.3.1) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim==4.3.1) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdNWSQYDQ0hn",
        "outputId": "a9def4d8-dbe0-49b3-9397-21b461b7e620"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.2.2)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (4.3.1)\n",
            "Collecting transformers==4.27.1\n",
            "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->-r requirements.txt (line 3)) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->-r requirements.txt (line 3)) (1.11.1)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->-r requirements.txt (line 3)) (3.10.7)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->-r requirements.txt (line 3)) (3.1.2)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->-r requirements.txt (line 3)) (4.5.0)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 3)) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 3)) (67.6.1)\n",
            "Collecting lit\n",
            "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 3)) (3.25.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (23.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.32.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (16.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.53.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.4.7)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.20.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim->-r requirements.txt (line 6)) (6.3.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.104-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow->-r requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (3.4.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (2.17.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (2022.12.7)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.104\n",
            "  Downloading botocore-1.29.104-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->-r requirements.txt (line 3)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.104->boto3->pytorch-pretrained-bert->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 4)) (3.2.2)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=4c371e15c366fbfd27bacded01257cb1fded9d0c76393430a2713f5dd4941059\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n",
            "Successfully built lit\n",
            "Installing collected packages: tokenizers, lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jmespath, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, botocore, transformers, s3transfer, boto3, triton, torch, pytorch-pretrained-bert\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.26.104 botocore-1.29.104 huggingface-hub-0.13.3 jmespath-1.0.1 lit-16.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 tokenizers-0.13.2 torch-2.0.0 transformers-4.27.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **in the next line, use !python3 main.py \\<model_name> with \\<model_name> either \"word2vec_model\", \"bert_pretrained\" or \"distilbert-base-uncased\"**\n",
        "NB: \"distilbert-base-uncased\" doesn't work yet"
      ],
      "metadata": {
        "id": "msr2iAxyb-ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py word2vec_model"
      ],
      "metadata": {
        "id": "KKE0T1HFqEKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089ff088-a154-4bc5-a679-144a1edefd9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14370\n",
            "[['after that', 'template'], ['the doctor answers questionnaires', 'activity'], ['after that', 'template'], ['the above sequential part is finished', 'template'], ['at last', 'template'], ['the process ends', 'template'], ['the process begins when there are some procedures need to be finished sequentially', 'template'], ['one of the following branches is executed', 'template'], ['the administrator documents modification process', 'activity'], ['after that', 'template']]\n",
            "{'activity', 'template'}\n",
            "8622\n",
            "[['when the above path is finished', 'end'], ['one of the following branches is executed', 'xor_begin'], ['after that', 'then'], ['after that', 'then'], ['when the above path is finished', 'end'], ['then', 'then'], ['then', 'then'], ['the above sequential part is finished', 'end'], ['at last', 'then'], ['the process ends', 'end']]\n",
            "{'polygon_begin', 'loop_begin', 'then', 'and_begin', 'end', 'xor_begin'}\n",
            "28174\n",
            "[['the writer prints account', '0', 'none'], ['the writer prints account', '1', 'role'], ['the writer prints account', '2', 'action'], ['the writer prints account', '3', 'object'], ['the server reversals invoice', '0', 'none'], ['the server reversals invoice', '1', 'role'], ['the server reversals invoice', '2', 'action'], ['the server reversals invoice', '3', 'object'], ['the sommelier forecasts', '0', 'none'], ['the sommelier forecasts', '1', 'role']]\n",
            "{'action', 'role', 'none', 'object'}\n",
            "11496 2874\n",
            "6897 1725\n",
            "22539 5635\n",
            "[   0]    recall:58.4739%    precision:69.7349%    macrof1:43.4373%    microf1:46.9381%    accuracy:46.9381%\n",
            "[   1]    recall:58.4739%    precision:69.7349%    macrof1:43.4373%    microf1:46.9381%    accuracy:46.9381%\n",
            "[   2]    recall:58.4739%    precision:69.7349%    macrof1:43.4373%    microf1:46.9381%    accuracy:46.9381%\n",
            "[   3]    recall:59.7518%    precision:70.1737%    macrof1:45.6365%    microf1:48.5734%    accuracy:48.5734%\n",
            "[   4]    recall:59.7518%    precision:70.1737%    macrof1:45.6365%    microf1:48.5734%    accuracy:48.5734%\n",
            "[   5]    recall:61.1656%    precision:70.6603%    macrof1:47.9936%    microf1:50.3827%    accuracy:50.3827%\n",
            "[   6]    recall:61.1656%    precision:70.6603%    macrof1:47.9936%    microf1:50.3827%    accuracy:50.3827%\n",
            "[   7]    recall:61.1656%    precision:70.6603%    macrof1:47.9936%    microf1:50.3827%    accuracy:50.3827%\n",
            "[   8]    recall:61.1656%    precision:70.6603%    macrof1:47.9936%    microf1:50.3827%    accuracy:50.3827%\n",
            "[   9]    recall:61.2471%    precision:70.6886%    macrof1:48.1273%    microf1:50.4871%    accuracy:50.4871%\n",
            "[  10]    recall:62.4434%    precision:71.1067%    macrof1:50.0606%    microf1:52.0181%    accuracy:52.0181%\n",
            "[  11]    recall:62.4434%    precision:71.1067%    macrof1:50.0606%    microf1:52.0181%    accuracy:52.0181%\n",
            "[  12]    recall:63.2319%    precision:71.3868%    macrof1:51.3082%    microf1:53.0271%    accuracy:53.0271%\n",
            "[  13]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  14]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  15]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  16]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  17]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  18]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  19]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  20]    recall:70.3553%    precision:74.1760%    macrof1:61.7858%    microf1:62.1434%    accuracy:62.1434%\n",
            "[  21]    recall:70.4369%    precision:74.2113%    macrof1:61.8989%    microf1:62.2477%    accuracy:62.2477%\n",
            "[  22]    recall:70.4369%    precision:74.2113%    macrof1:61.8989%    microf1:62.2477%    accuracy:62.2477%\n",
            "[  23]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  24]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  25]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  26]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  27]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  28]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  29]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  30]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  31]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  32]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  33]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  34]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  35]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  36]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  37]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  38]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  39]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  40]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  41]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  42]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  43]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  44]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  45]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  46]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  47]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  48]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  49]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  50]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  51]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  52]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  53]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  54]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  55]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  56]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  57]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  58]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  59]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  60]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  61]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  62]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  63]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  64]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  65]    recall:72.0410%    precision:74.9263%    macrof1:64.0978%    microf1:64.3006%    accuracy:64.3006%\n",
            "[  66]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  67]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  68]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  69]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  70]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  71]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  72]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  73]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  74]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  75]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  76]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  77]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  78]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  79]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  80]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  81]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  82]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  83]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  84]    recall:79.4092%    precision:78.7862%    macrof1:73.7204%    microf1:73.7300%    accuracy:73.7300%\n",
            "[  85]    recall:79.4575%    precision:78.8437%    macrof1:73.7555%    microf1:73.7648%    accuracy:73.7648%\n",
            "[  86]    recall:79.4575%    precision:78.8437%    macrof1:73.7555%    microf1:73.7648%    accuracy:73.7648%\n",
            "[  87]    recall:82.0132%    precision:80.4595%    macrof1:76.9744%    microf1:77.0355%    accuracy:77.0355%\n",
            "[  88]    recall:82.0132%    precision:80.4595%    macrof1:76.9744%    microf1:77.0355%    accuracy:77.0355%\n",
            "[  89]    recall:82.0132%    precision:80.4595%    macrof1:76.9744%    microf1:77.0355%    accuracy:77.0355%\n",
            "[  90]    recall:82.0132%    precision:80.4595%    macrof1:76.9744%    microf1:77.0355%    accuracy:77.0355%\n",
            "[  91]    recall:82.0132%    precision:80.4595%    macrof1:76.9744%    microf1:77.0355%    accuracy:77.0355%\n",
            "[  92]    recall:82.0132%    precision:80.4595%    macrof1:76.9744%    microf1:77.0355%    accuracy:77.0355%\n",
            "[  93]    recall:85.1943%    precision:82.7376%    macrof1:80.9445%    microf1:81.1065%    accuracy:81.1065%\n",
            "[  94]    recall:85.1943%    precision:82.7376%    macrof1:80.9445%    microf1:81.1065%    accuracy:81.1065%\n",
            "[  95]    recall:85.1943%    precision:82.7376%    macrof1:80.9445%    microf1:81.1065%    accuracy:81.1065%\n",
            "[  96]    recall:85.1943%    precision:82.7376%    macrof1:80.9445%    microf1:81.1065%    accuracy:81.1065%\n",
            "[  97]    recall:86.2818%    precision:83.5955%    macrof1:82.2989%    microf1:82.4983%    accuracy:82.4983%\n",
            "[  98]    recall:86.2818%    precision:83.5955%    macrof1:82.2989%    microf1:82.4983%    accuracy:82.4983%\n",
            "[  99]    recall:86.2818%    precision:83.5955%    macrof1:82.2989%    microf1:82.4983%    accuracy:82.4983%\n",
            "[   0]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   1]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   2]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   3]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   4]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   5]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   6]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   7]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   8]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[   9]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  10]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  11]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  12]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  13]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  14]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  15]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  16]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  17]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  18]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  19]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  20]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  21]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  22]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  23]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  24]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  25]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  26]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  27]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  28]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  29]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  30]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  31]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  32]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  33]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  34]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  35]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  36]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  37]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  38]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  39]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  40]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  41]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  42]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  43]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  44]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  45]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  46]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  47]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  48]    recall:16.6667%    precision:1.4686%    macrof1:2.6993%    microf1:8.8116%    accuracy:8.8116%\n",
            "[  49]    recall:18.4241%    precision:18.2171%    macrof1:6.0165%    microf1:14.0870%    accuracy:14.0870%\n",
            "[  50]    recall:18.4241%    precision:18.2171%    macrof1:6.0165%    microf1:14.0870%    accuracy:14.0870%\n",
            "[  51]    recall:18.4241%    precision:18.2171%    macrof1:6.0165%    microf1:14.0870%    accuracy:14.0870%\n",
            "[  52]    recall:18.4241%    precision:18.2171%    macrof1:6.0165%    microf1:14.0870%    accuracy:14.0870%\n",
            "[  53]    recall:18.4241%    precision:18.2171%    macrof1:6.0165%    microf1:14.0870%    accuracy:14.0870%\n",
            "[  54]    recall:18.4241%    precision:18.2171%    macrof1:6.0165%    microf1:14.0870%    accuracy:14.0870%\n",
            "[  55]    recall:18.4241%    precision:18.2171%    macrof1:6.0165%    microf1:14.0870%    accuracy:14.0870%\n",
            "[  56]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  57]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  58]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  59]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  60]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  61]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  62]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  63]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  64]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  65]    recall:23.4260%    precision:18.5091%    macrof1:12.9361%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  66]    recall:23.4260%    precision:16.4604%    macrof1:12.6627%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  67]    recall:23.4260%    precision:16.4604%    macrof1:12.6627%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  68]    recall:23.4260%    precision:16.4604%    macrof1:12.6627%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  69]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  70]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  71]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  72]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  73]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  74]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  75]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  76]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  77]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  78]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  79]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  80]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  81]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  82]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  83]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  84]    recall:23.4260%    precision:16.4256%    macrof1:12.6577%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  85]    recall:23.4260%    precision:14.6579%    macrof1:12.3898%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  86]    recall:23.4260%    precision:14.6579%    macrof1:12.3898%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  87]    recall:23.4260%    precision:14.6579%    macrof1:12.3898%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  88]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  89]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  90]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  91]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  92]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  93]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  94]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  95]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  96]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  97]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  98]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[  99]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 100]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 101]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 102]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 103]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 104]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 105]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 106]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 107]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 108]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 109]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 110]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 111]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 112]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 113]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 114]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 115]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 116]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 117]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 118]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 119]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 120]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 121]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 122]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 123]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 124]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 125]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 126]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 127]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 128]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 129]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 130]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 131]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 132]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 133]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 134]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 135]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 136]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 137]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 138]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 139]    recall:23.4260%    precision:14.5808%    macrof1:12.3775%    microf1:29.1014%    accuracy:29.1014%\n",
            "[ 140]    recall:28.1769%    precision:16.4865%    macrof1:16.9714%    microf1:43.3623%    accuracy:43.3623%\n",
            "[ 141]    recall:28.1769%    precision:16.4865%    macrof1:16.9714%    microf1:43.3623%    accuracy:43.3623%\n",
            "[ 142]    recall:28.1769%    precision:16.4865%    macrof1:16.9714%    microf1:43.3623%    accuracy:43.3623%\n",
            "[ 143]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 144]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 145]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 146]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 147]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 148]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 149]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 150]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 151]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 152]    recall:33.3333%    precision:18.1087%    macrof1:21.2637%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 153]    recall:33.3333%    precision:17.6262%    macrof1:21.1802%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 154]    recall:33.3333%    precision:17.6262%    macrof1:21.1802%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 155]    recall:33.3333%    precision:17.6262%    macrof1:21.1802%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 156]    recall:33.3333%    precision:17.6262%    macrof1:21.1802%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 157]    recall:33.3333%    precision:17.6262%    macrof1:21.1802%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 158]    recall:33.3333%    precision:17.6262%    macrof1:21.1802%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 159]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 160]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 161]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 162]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 163]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 164]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 165]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 166]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 167]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 168]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 169]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 170]    recall:33.3333%    precision:17.6012%    macrof1:21.1773%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 171]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 172]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 173]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 174]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 175]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 176]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 177]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 178]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 179]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 180]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 181]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 182]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 183]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 184]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 185]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 186]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 187]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 188]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 189]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 190]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 191]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 192]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 193]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 194]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 195]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 196]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 197]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 198]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[ 199]    recall:33.3333%    precision:17.2773%    macrof1:21.1610%    microf1:58.8406%    accuracy:58.8406%\n",
            "[   0]    recall:22.5017%    precision:11.9380%    macrof1:13.6821%    microf1:35.4215%    accuracy:35.4215%\n",
            "[   1]    recall:22.5240%    precision:11.9635%    macrof1:13.6926%    microf1:35.4570%    accuracy:35.4570%\n",
            "[   2]    recall:22.5464%    precision:11.9894%    macrof1:13.7028%    microf1:35.4925%    accuracy:35.4925%\n",
            "[   3]    recall:22.5358%    precision:11.7714%    macrof1:13.6400%    microf1:35.5102%    accuracy:35.5102%\n",
            "[   4]    recall:22.5582%    precision:11.7967%    macrof1:13.6501%    microf1:35.5457%    accuracy:35.5457%\n",
            "[   5]    recall:22.5920%    precision:11.7251%    macrof1:13.6363%    microf1:35.6167%    accuracy:35.6167%\n",
            "[   6]    recall:22.6256%    precision:11.7610%    macrof1:13.6518%    microf1:35.6699%    accuracy:35.6699%\n",
            "[   7]    recall:22.6703%    precision:11.8103%    macrof1:13.6725%    microf1:35.7409%    accuracy:35.7409%\n",
            "[   8]    recall:22.6926%    precision:11.8350%    macrof1:13.6830%    microf1:35.7764%    accuracy:35.7764%\n",
            "[   9]    recall:22.7597%    precision:11.9147%    macrof1:13.7136%    microf1:35.8829%    accuracy:35.8829%\n",
            "[  10]    recall:22.8044%    precision:11.9693%    macrof1:13.7342%    microf1:35.9539%    accuracy:35.9539%\n",
            "[  11]    recall:22.7494%    precision:11.5252%    macrof1:13.6186%    microf1:35.9184%    accuracy:35.9184%\n",
            "[  12]    recall:22.7606%    precision:11.5366%    macrof1:13.6237%    microf1:35.9361%    accuracy:35.9361%\n",
            "[  13]    recall:22.7718%    precision:11.5481%    macrof1:13.6287%    microf1:35.9539%    accuracy:35.9539%\n",
            "[  14]    recall:22.7830%    precision:11.5597%    macrof1:13.6338%    microf1:35.9716%    accuracy:35.9716%\n",
            "[  15]    recall:22.8165%    precision:11.5972%    macrof1:13.6488%    microf1:36.0248%    accuracy:36.0248%\n",
            "[  16]    recall:22.8171%    precision:11.3160%    macrof1:13.5876%    microf1:36.0603%    accuracy:36.0603%\n",
            "[  17]    recall:22.7953%    precision:10.9975%    macrof1:13.5159%    microf1:36.0603%    accuracy:36.0603%\n",
            "[  18]    recall:22.8177%    precision:11.0135%    macrof1:13.5258%    microf1:36.0958%    accuracy:36.0958%\n",
            "[  19]    recall:22.8177%    precision:11.0135%    macrof1:13.5258%    microf1:36.0958%    accuracy:36.0958%\n",
            "[  20]    recall:22.8289%    precision:11.0216%    macrof1:13.5307%    microf1:36.1136%    accuracy:36.1136%\n",
            "[  21]    recall:22.8512%    precision:11.0445%    macrof1:13.5406%    microf1:36.1491%    accuracy:36.1491%\n",
            "[  22]    recall:22.8848%    precision:11.0695%    macrof1:13.5553%    microf1:36.2023%    accuracy:36.2023%\n",
            "[  23]    recall:22.9071%    precision:11.0999%    macrof1:13.5651%    microf1:36.2378%    accuracy:36.2378%\n",
            "[  24]    recall:22.9071%    precision:11.0999%    macrof1:13.5651%    microf1:36.2378%    accuracy:36.2378%\n",
            "[  25]    recall:22.8960%    precision:11.0845%    macrof1:13.5602%    microf1:36.2201%    accuracy:36.2201%\n",
            "[  26]    recall:22.8960%    precision:11.0780%    macrof1:13.5602%    microf1:36.2201%    accuracy:36.2201%\n",
            "[  27]    recall:22.9407%    precision:11.1190%    macrof1:13.5799%    microf1:36.2910%    accuracy:36.2910%\n",
            "[  28]    recall:22.9407%    precision:11.1190%    macrof1:13.5799%    microf1:36.2910%    accuracy:36.2910%\n",
            "[  29]    recall:22.9298%    precision:10.9369%    macrof1:13.5435%    microf1:36.2910%    accuracy:36.2910%\n",
            "[  30]    recall:22.9522%    precision:10.9519%    macrof1:13.5533%    microf1:36.3265%    accuracy:36.3265%\n",
            "[  31]    recall:22.9857%    precision:10.9750%    macrof1:13.5679%    microf1:36.3798%    accuracy:36.3798%\n",
            "[  32]    recall:23.0081%    precision:10.9983%    macrof1:13.5777%    microf1:36.4153%    accuracy:36.4153%\n",
            "[  33]    recall:23.0084%    precision:10.8170%    macrof1:13.5459%    microf1:36.4330%    accuracy:36.4330%\n",
            "[  34]    recall:23.0195%    precision:10.8234%    macrof1:13.5507%    microf1:36.4508%    accuracy:36.4508%\n",
            "[  35]    recall:23.0754%    precision:10.8961%    macrof1:13.5751%    microf1:36.5395%    accuracy:36.5395%\n",
            "[  36]    recall:23.0866%    precision:10.9025%    macrof1:13.5799%    microf1:36.5572%    accuracy:36.5572%\n",
            "[  37]    recall:23.0866%    precision:10.9025%    macrof1:13.5799%    microf1:36.5572%    accuracy:36.5572%\n",
            "[  38]    recall:23.0866%    precision:10.9025%    macrof1:13.5799%    microf1:36.5572%    accuracy:36.5572%\n",
            "[  39]    recall:23.1202%    precision:10.9224%    macrof1:13.5944%    microf1:36.6105%    accuracy:36.6105%\n",
            "[  40]    recall:23.1425%    precision:10.9359%    macrof1:13.6040%    microf1:36.6460%    accuracy:36.6460%\n",
            "[  41]    recall:23.1649%    precision:10.9603%    macrof1:13.6137%    microf1:36.6815%    accuracy:36.6815%\n",
            "[  42]    recall:23.2320%    precision:11.0248%    macrof1:13.6427%    microf1:36.7879%    accuracy:36.7879%\n",
            "[  43]    recall:23.2655%    precision:11.0702%    macrof1:13.6573%    microf1:36.8412%    accuracy:36.8412%\n",
            "[  44]    recall:23.2434%    precision:10.8349%    macrof1:13.6152%    microf1:36.8234%    accuracy:36.8234%\n",
            "[  45]    recall:23.2658%    precision:10.8452%    macrof1:13.6247%    microf1:36.8589%    accuracy:36.8589%\n",
            "[  46]    recall:23.2882%    precision:10.8702%    macrof1:13.6344%    microf1:36.8944%    accuracy:36.8944%\n",
            "[  47]    recall:23.3105%    precision:10.8958%    macrof1:13.6440%    microf1:36.9299%    accuracy:36.9299%\n",
            "[  48]    recall:23.3105%    precision:10.8958%    macrof1:13.6440%    microf1:36.9299%    accuracy:36.9299%\n",
            "[  49]    recall:23.3329%    precision:10.9065%    macrof1:13.6535%    microf1:36.9654%    accuracy:36.9654%\n",
            "[  50]    recall:23.3553%    precision:10.9173%    macrof1:13.6631%    microf1:37.0009%    accuracy:37.0009%\n",
            "[  51]    recall:23.3888%    precision:10.9340%    macrof1:13.6774%    microf1:37.0541%    accuracy:37.0541%\n",
            "[  52]    recall:23.3888%    precision:10.9340%    macrof1:13.6774%    microf1:37.0541%    accuracy:37.0541%\n",
            "[  53]    recall:23.4000%    precision:10.9397%    macrof1:13.6821%    microf1:37.0719%    accuracy:37.0719%\n",
            "[  54]    recall:23.4112%    precision:10.9455%    macrof1:13.6869%    microf1:37.0896%    accuracy:37.0896%\n",
            "[  55]    recall:23.4112%    precision:10.9455%    macrof1:13.6869%    microf1:37.0896%    accuracy:37.0896%\n",
            "[  56]    recall:23.4223%    precision:10.9513%    macrof1:13.6917%    microf1:37.1074%    accuracy:37.1074%\n",
            "[  57]    recall:23.4223%    precision:10.9513%    macrof1:13.6917%    microf1:37.1074%    accuracy:37.1074%\n",
            "[  58]    recall:23.4671%    precision:10.9900%    macrof1:13.7108%    microf1:37.1783%    accuracy:37.1783%\n",
            "[  59]    recall:23.5230%    precision:11.0212%    macrof1:13.7345%    microf1:37.2671%    accuracy:37.2671%\n",
            "[  60]    recall:23.5677%    precision:11.0623%    macrof1:13.7536%    microf1:37.3381%    accuracy:37.3381%\n",
            "[  61]    recall:23.6012%    precision:11.0829%    macrof1:13.7678%    microf1:37.3913%    accuracy:37.3913%\n",
            "[  62]    recall:23.6015%    precision:10.7621%    macrof1:13.7342%    microf1:37.4091%    accuracy:37.4091%\n",
            "[  63]    recall:23.6574%    precision:10.7762%    macrof1:13.7577%    microf1:37.4978%    accuracy:37.4978%\n",
            "[  64]    recall:23.6910%    precision:10.8038%    macrof1:13.7719%    microf1:37.5510%    accuracy:37.5510%\n",
            "[  65]    recall:23.7022%    precision:10.8066%    macrof1:13.7766%    microf1:37.5688%    accuracy:37.5688%\n",
            "[  66]    recall:23.7133%    precision:10.8094%    macrof1:13.7813%    microf1:37.5865%    accuracy:37.5865%\n",
            "[  67]    recall:23.7245%    precision:10.8320%    macrof1:13.7861%    microf1:37.6043%    accuracy:37.6043%\n",
            "[  68]    recall:23.7469%    precision:10.8376%    macrof1:13.7954%    microf1:37.6398%    accuracy:37.6398%\n",
            "[  69]    recall:23.7581%    precision:10.8404%    macrof1:13.8001%    microf1:37.6575%    accuracy:37.6575%\n",
            "[  70]    recall:23.7581%    precision:10.8404%    macrof1:13.8001%    microf1:37.6575%    accuracy:37.6575%\n",
            "[  71]    recall:23.7916%    precision:10.8692%    macrof1:13.8143%    microf1:37.7107%    accuracy:37.7107%\n",
            "[  72]    recall:23.8140%    precision:10.8748%    macrof1:13.8237%    microf1:37.7462%    accuracy:37.7462%\n",
            "[  73]    recall:23.8251%    precision:10.8776%    macrof1:13.8283%    microf1:37.7640%    accuracy:37.7640%\n",
            "[  74]    recall:23.8475%    precision:10.9043%    macrof1:13.8378%    microf1:37.7995%    accuracy:37.7995%\n",
            "[  75]    recall:23.8475%    precision:10.9043%    macrof1:13.8378%    microf1:37.7995%    accuracy:37.7995%\n",
            "[  76]    recall:23.8587%    precision:10.9290%    macrof1:13.8426%    microf1:37.8172%    accuracy:37.8172%\n",
            "[  77]    recall:23.8587%    precision:10.9290%    macrof1:13.8426%    microf1:37.8172%    accuracy:37.8172%\n",
            "[  78]    recall:23.8587%    precision:10.9290%    macrof1:13.8426%    microf1:37.8172%    accuracy:37.8172%\n",
            "[  79]    recall:23.8699%    precision:10.9318%    macrof1:13.8473%    microf1:37.8350%    accuracy:37.8350%\n",
            "[  80]    recall:23.9593%    precision:11.0246%    macrof1:13.8850%    microf1:37.9769%    accuracy:37.9769%\n",
            "[  81]    recall:23.9817%    precision:11.0301%    macrof1:13.8943%    microf1:38.0124%    accuracy:38.0124%\n",
            "[  82]    recall:24.0264%    precision:11.1482%    macrof1:13.9134%    microf1:38.0834%    accuracy:38.0834%\n",
            "[  83]    recall:24.0376%    precision:11.1509%    macrof1:13.9180%    microf1:38.1012%    accuracy:38.1012%\n",
            "[  84]    recall:24.0711%    precision:11.2511%    macrof1:13.9323%    microf1:38.1544%    accuracy:38.1544%\n",
            "[  85]    recall:24.1158%    precision:11.3663%    macrof1:13.9512%    microf1:38.2254%    accuracy:38.2254%\n",
            "[  86]    recall:24.1270%    precision:11.3691%    macrof1:13.9559%    microf1:38.2431%    accuracy:38.2431%\n",
            "[  87]    recall:24.1382%    precision:11.3719%    macrof1:13.9605%    microf1:38.2609%    accuracy:38.2609%\n",
            "[  88]    recall:24.1606%    precision:11.4153%    macrof1:13.9699%    microf1:38.2964%    accuracy:38.2964%\n",
            "[  89]    recall:24.1717%    precision:11.4576%    macrof1:13.9747%    microf1:38.3141%    accuracy:38.3141%\n",
            "[  90]    recall:24.1829%    precision:11.4604%    macrof1:13.9793%    microf1:38.3319%    accuracy:38.3319%\n",
            "[  91]    recall:24.2388%    precision:11.4742%    macrof1:14.0025%    microf1:38.4206%    accuracy:38.4206%\n",
            "[  92]    recall:24.2612%    precision:11.4797%    macrof1:14.0118%    microf1:38.4561%    accuracy:38.4561%\n",
            "[  93]    recall:24.2835%    precision:11.4851%    macrof1:14.0211%    microf1:38.4916%    accuracy:38.4916%\n",
            "[  94]    recall:24.2835%    precision:11.4851%    macrof1:14.0211%    microf1:38.4916%    accuracy:38.4916%\n",
            "[  95]    recall:24.3056%    precision:12.0154%    macrof1:14.0652%    microf1:38.5093%    accuracy:38.5093%\n",
            "[  96]    recall:24.3056%    precision:12.0154%    macrof1:14.0652%    microf1:38.5093%    accuracy:38.5093%\n",
            "[  97]    recall:24.3168%    precision:12.0182%    macrof1:14.0699%    microf1:38.5271%    accuracy:38.5271%\n",
            "[  98]    recall:24.3280%    precision:12.0209%    macrof1:14.0745%    microf1:38.5448%    accuracy:38.5448%\n",
            "[  99]    recall:24.3392%    precision:12.0237%    macrof1:14.0791%    microf1:38.5626%    accuracy:38.5626%\n",
            "[ 100]    recall:24.3615%    precision:12.0820%    macrof1:14.0885%    microf1:38.5980%    accuracy:38.5980%\n",
            "[ 101]    recall:24.3727%    precision:12.1401%    macrof1:14.0933%    microf1:38.6158%    accuracy:38.6158%\n",
            "[ 102]    recall:24.4062%    precision:12.2064%    macrof1:14.1073%    microf1:38.6690%    accuracy:38.6690%\n",
            "[ 103]    recall:24.4398%    precision:12.2756%    macrof1:14.1213%    microf1:38.7223%    accuracy:38.7223%\n",
            "[ 104]    recall:24.4730%    precision:12.9051%    macrof1:14.1703%    microf1:38.7578%    accuracy:38.7578%\n",
            "[ 105]    recall:24.4954%    precision:12.9105%    macrof1:14.1796%    microf1:38.7933%    accuracy:38.7933%\n",
            "[ 106]    recall:24.5178%    precision:12.9961%    macrof1:14.1890%    microf1:38.8287%    accuracy:38.8287%\n"
          ]
        }
      ]
    }
  ]
}